{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Net basics: Part One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you're like me, learning about neural net could be pretty confusing. As a curious person who just wants to see this so called _neural network_ in action. Materials on the internet about neural networks could be so confusing (too mathematical or too much code). So I decided to make the best of both. Teach you what you'll need to get started developing neural networks.\n",
    "\n",
    "Let's build a two layer neural network to predict the mappings between binary digits. The only dependency needed is [`numpy`](https://pypi.python.org/pypi/numpy). If you're not familar with [`numpy`](http://www.numpy.org/) it's okay. You'll still be able to follow up just fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After installing numpy by running `pip install numpy` or downloading it [here](https://pypi.python.org/pypi/numpy). We're gonna want to import `numpy`. It's common convention to import numpy as `np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The only dependency required.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us define our two inputs, shall we."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array([ [0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1] ])\n",
    "y = np.array([ [0], [1], [1], [0] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`X` is our input/feature, while `y` is our target/label. Features in machine learning are the relevant information about a piece of data. for example: if I want to predict the score of the next soccer match, it'll be nice if I have player's statistics and past match history (I'm not a soccer fan). Those statistics represent our features while the score can be our target/labels, since that's what we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we understand what features and labels are. It's time to define some [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)). Hyperparameters in machine learning are the tuning knobs for our network. For instance, how many layers do we want? How many training iterations do we want to perform? Usually, one wouldn't know what the best hyperparameters are right off the bat. You'll need some tweaking to know the best set of hyperparameters to use. In this case we're gonna keep it simple. Let's define our _input dimension_, _hidden dimension_ and _output dimension_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 3\n",
      "Hidden dimension: 4\n",
      "Ouput dimension: 1\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[-1]\n",
    "hidden_dim = 4\n",
    "output_dim = y.shape[-1]\n",
    "print('Input dimension: {}\\nHidden dimension: {}\\nOuput dimension: {}'.format(input_dim, hidden_dim, output_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W0 = 2 * np.random.random(size=[input_dim, hidden_dim]) - 1\n",
    "W1 = 2 * np.random.random(size=[hidden_dim, output_dim]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z, prime=False):\n",
    "    if prime:\n",
    "        return Z * (1 - Z)\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sigmoid activation function ![Sigmoid](images/sigmoid.png)\n",
    "\n",
    "Sigmoid derivative ![Sigmoid derivative](images/sigmoid-deriv-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    l1 = sigmoid(np.dot(X, W0))\n",
    "    l2 = sigmoid(np.dot(l1, W1))\n",
    "    l2_error = (y - l2) ** 2\n",
    "    l2_delta = l2_error * sigmoid(l2, prime=True)\n",
    "    l1_error = np.dot(l2_delta, W1.T)\n",
    "    l1_delta = l1_error * sigmoid(l1, prime=True)\n",
    "    W1 += np.dot(l1.T, l2_delta)\n",
    "    W0 += np.dot(X.T, l1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
